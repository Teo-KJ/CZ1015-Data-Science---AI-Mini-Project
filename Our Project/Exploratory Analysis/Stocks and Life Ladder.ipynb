{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot,iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Essential Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interploation_1d(life_ladder_data, no_of_years, no_of_days, power):\n",
    "    num = range(0, no_of_years)\n",
    "    x = np.array(tuple(num))\n",
    "    y = np.array(life_ladder_data)\n",
    "    z = np.polyfit(x, y, power)\n",
    "    f = np.poly1d(z)\n",
    "    num_1 = no_of_years - 1\n",
    "    x_new = np.linspace(0, num_1, no_of_days)\n",
    "    y_new = f(x_new)\n",
    "    print(\"The interpolated y-values are:\\n\", y_new)\n",
    "    print(\"Total:\", len(y_new), \"datapoints generated for this specific diagram.\")\n",
    "    trace1 = go.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        mode='markers',\n",
    "        name='Data',\n",
    "        marker=dict(\n",
    "            size=12))\n",
    "    trace2 = go.Scatter(\n",
    "        x=x_new,\n",
    "        y=y_new,\n",
    "        mode='lines',\n",
    "        name='Fit')\n",
    "    annotation = go.Annotation(\n",
    "        x=1,\n",
    "        y=1,\n",
    "        showarrow=False)\n",
    "    layout = go.Layout(title='Polynomial Fit in Python',\n",
    "                       annotations=[annotation])\n",
    "    data = [trace1, trace2]\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)\n",
    "    return y_new\n",
    "\n",
    "def interploation_1d_custom(life_ladder_data, no_of_years, no_of_days, power, avg_data):\n",
    "    num = range(0, no_of_years)\n",
    "    x = np.array(tuple(num))\n",
    "    y = np.array(life_ladder_data)\n",
    "#     y2 = np.array(avg_data)\n",
    "    z = np.polyfit(x, y, power)\n",
    "    f = np.poly1d(z)\n",
    "    num_1 = no_of_years - 1\n",
    "    x_new = np.linspace(0, num_1, no_of_days)\n",
    "    y_new = f(x_new)\n",
    "    print(\"The interpolated y-values are:\\n\", y_new)\n",
    "    print(\"Total:\", len(y_new), \"datapoints generated for this specific diagram.\")\n",
    "    trace1 = go.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        mode='markers',\n",
    "        name='Data',\n",
    "        marker=dict(\n",
    "            size=12,\n",
    "            color = 'red'))\n",
    "    trace2 = go.Scatter(\n",
    "        x=x_new,\n",
    "        y=y_new,\n",
    "        mode='lines',\n",
    "        name='Fit')\n",
    "    trace3 = go.Scatter(\n",
    "        x=x,\n",
    "        y=avg_data,\n",
    "        mode='markers',\n",
    "        name='Average',\n",
    "        marker=dict(\n",
    "            size=12,\n",
    "            color = 'green'))\n",
    "    annotation = go.Annotation(\n",
    "        x=1,\n",
    "        y=1,\n",
    "        showarrow=False)\n",
    "    layout = go.Layout(title='Polynomial Fit in Python',\n",
    "                       annotations=[annotation])\n",
    "    data = [trace1, trace3, trace2]\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)\n",
    "    return y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stocks_data_1(data):\n",
    "    data[\"Log10_volume\"] = np.log10(data['Volume'])\n",
    "    data[\"Average\"] = (data[\"High\"] + data[\"Low\"])/2\n",
    "    data[\"Perc Diff\"] = ((data['High']-data['Low'])/data['High'])*100\n",
    "    data[\"Delta\"] = ((data['High']-data['Low']))\n",
    "    \n",
    "    Stocks_2006 = pd.DataFrame(data[data['Date'].str.contains('/2006')])\n",
    "    Stocks_2007 = pd.DataFrame(data[data['Date'].str.contains('/2007')])\n",
    "    Stocks_2008 = pd.DataFrame(data[data['Date'].str.contains('/2008')])\n",
    "    Stocks_2009 = pd.DataFrame(data[data['Date'].str.contains('/2009')])\n",
    "    Stocks_2010 = pd.DataFrame(data[data['Date'].str.contains('/2010')])\n",
    "    Stocks_2011 = pd.DataFrame(data[data['Date'].str.contains('/2011')])\n",
    "    Stocks_2012 = pd.DataFrame(data[data['Date'].str.contains('/2012')])\n",
    "    Stocks_2013 = pd.DataFrame(data[data['Date'].str.contains('/2013')])\n",
    "    Stocks_2014 = pd.DataFrame(data[data['Date'].str.contains('/2014')])\n",
    "    Stocks_2015 = pd.DataFrame(data[data['Date'].str.contains('/2015')])\n",
    "    Stocks_2016 = pd.DataFrame(data[data['Date'].str.contains('/2016')])\n",
    "    Stocks_2017 = pd.DataFrame(data[data['Date'].str.contains('/2017')])\n",
    "    Stocks_2018 = pd.DataFrame(data[data['Date'].str.contains('/2018')])\n",
    "    \n",
    "    frames = [Stocks_2006, Stocks_2007, Stocks_2008, Stocks_2009, Stocks_2010, Stocks_2011, Stocks_2012, Stocks_2013,\n",
    "              Stocks_2014, Stocks_2015, Stocks_2016, Stocks_2017, Stocks_2018]\n",
    "    \n",
    "    Resulting_Data = pd.concat(frames)\n",
    "    print(\"Total number of days:\", len(Resulting_Data))\n",
    "    return Resulting_Data\n",
    "\n",
    "def stocks_data_2(data):\n",
    "    data[\"Log10_volume\"] = np.log10(data['Volume'])\n",
    "    data[\"Average\"] = (data[\"High\"] + data[\"Low\"])/2\n",
    "    data[\"Perc Diff\"] = ((data['High']-data['Low'])/data['High'])*100\n",
    "    data[\"Delta\"] = ((data['High']-data['Low']))\n",
    "    \n",
    "    Stocks_2006 = pd.DataFrame(data[data['Date'].str.contains('2006-')])\n",
    "    Stocks_2007 = pd.DataFrame(data[data['Date'].str.contains('2007-')])\n",
    "    Stocks_2008 = pd.DataFrame(data[data['Date'].str.contains('2008-')])\n",
    "    Stocks_2009 = pd.DataFrame(data[data['Date'].str.contains('2009-')])\n",
    "    Stocks_2010 = pd.DataFrame(data[data['Date'].str.contains('2010-')])\n",
    "    Stocks_2011 = pd.DataFrame(data[data['Date'].str.contains('2011-')])\n",
    "    Stocks_2012 = pd.DataFrame(data[data['Date'].str.contains('2012-')])\n",
    "    Stocks_2013 = pd.DataFrame(data[data['Date'].str.contains('2013-')])\n",
    "    Stocks_2014 = pd.DataFrame(data[data['Date'].str.contains('2014-')])\n",
    "    Stocks_2015 = pd.DataFrame(data[data['Date'].str.contains('2015-')])\n",
    "    Stocks_2016 = pd.DataFrame(data[data['Date'].str.contains('2016-')])\n",
    "    Stocks_2017 = pd.DataFrame(data[data['Date'].str.contains('2017-')])\n",
    "    Stocks_2018 = pd.DataFrame(data[data['Date'].str.contains('2018-')])\n",
    "    \n",
    "    frames = [Stocks_2006, Stocks_2007, Stocks_2008, Stocks_2009, Stocks_2010, Stocks_2011, Stocks_2012, Stocks_2013,\n",
    "              Stocks_2014, Stocks_2015, Stocks_2016, Stocks_2017, Stocks_2018]\n",
    "    \n",
    "    Resulting_Data = pd.concat(frames)\n",
    "    print(\"Total number of days:\", len(Resulting_Data))\n",
    "    return Resulting_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_the_data_Stocks_n_LL(StocksData, NyrLLData):\n",
    "    StocksData.reset_index(drop=True)\n",
    "    StocksData.index = np.arange(1, len(StocksData)+1)\n",
    "    NyrLLData.reset_index(drop=True)\n",
    "    NyrLLData.index = np.arange(1, len(StocksData)+1)\n",
    "    combine = StocksData.join(NyrLLData)\n",
    "    \n",
    "    trace = go.Scatter(\n",
    "        x = combine['Date'],\n",
    "        y = combine['Daily Life Ladder'])\n",
    "    data = [trace]\n",
    "    iplot(data)\n",
    "    \n",
    "    return pd.DataFrame(combine)\n",
    "\n",
    "# PRC_Resulting_Stocks_Data.reset_index(drop=True)\n",
    "# PRC_Resulting_Stocks_Data.index = np.arange(1, len(PRC_Resulting_Stocks_Data)+1)\n",
    "# PRC_13yr_LL.reset_index(drop=True)\n",
    "# PRC_13yr_LL.index = np.arange(1, len(PRC_Resulting_Stocks_Data)+1)\n",
    "# PRC_Combine = Resulting_Data.join(PRCValues_for_13yr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hero Dataset Analysis - World Happiness Report of US (2006 - 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* d1 is the Overall Data for the past years since 2007 up till 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/World Happiness Report/WHR2019.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b44ddd855576>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data/World Happiness Report/WHR2019.xlsx\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Table2.1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# print(\"(No. of countries, No. of columns) =\", d1.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0md1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'Country'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mUS_Data\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Country name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"United States\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# print(\"(No. of Years, No. of columns) =\", US_Data.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, parse_cols, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skip_footer, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     return io.parse(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, engine)\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_stringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 653\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/World Happiness Report/WHR2019.xlsx'"
     ]
    }
   ],
   "source": [
    "d1 = pd.read_excel(\"Data/World Happiness Report/WHR2019.xlsx\", sheet_name='Table2.1')\n",
    "# print(\"(No. of countries, No. of columns) =\", d1.shape)\n",
    "d1 = d1.rename(columns={'country':'Country'})\n",
    "US_Data =  pd.DataFrame(d1[(d1['Country name'] == \"United States\")])\n",
    "# print(\"(No. of Years, No. of columns) =\", US_Data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_Data = US_Data[['Year', 'Life Ladder']]\n",
    "US_Data_LL = list(US_Data['Life Ladder'])\n",
    "# US_Data.sort_values(by = 'Life Ladder', ascending = False)\n",
    "print(len(US_Data))\n",
    "US_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting out the line plot of life ladder\n",
    "# trace = go.Scatter(\n",
    "#     x = US_Data['Year'],\n",
    "#     y = US_Data['Life Ladder'])\n",
    "# data = [trace]\n",
    "# iplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = len(US_Data_LL)\n",
    "days = 3270\n",
    "us_power = 10\n",
    "US_LL = interploation_1d(US_Data_LL, a, days, us_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values_for_13yr = pd.DataFrame({'Daily Life Ladder': y_new})\n",
    "US_LL = pd.DataFrame(data=US_LL)\n",
    "US_LL.columns = ['Daily Life Ladder']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Secondary Dataset Analysis - S&P500 for (2004 - 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_Stocks = pd.read_csv('Data\\Stocks\\S&P 500 (^GSPC)_2005to2018_daily.csv')\n",
    "US_Resulting_Stocks_Data = stocks_data_1(US_Stocks)\n",
    "US_Resulting_Stocks_Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining the 2 Datasets and Do Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "US_Combine = combine_the_data_Stocks_n_LL(US_Resulting_Stocks_Data, US_LL)\n",
    "US_Combine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## World Happiness Report of China (2006 - 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_excel(\"Data/World Happiness Report/WHR2019.xlsx\", sheet_name='Table2.1')\n",
    "# print(\"(No. of countries, No. of columns) =\", d1.shape)\n",
    "d1 = d1.rename(columns={'country':'Country'})\n",
    "China_Data =  pd.DataFrame(d1[(d1['Country name'] == \"China\")])\n",
    "# print(\"(No. of Years, No. of columns) =\", US_Data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extratcting the Dataset for Happiness and Stocks in China"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "China_Data = China_Data[['Year', 'Life Ladder']]\n",
    "China_Data_LL = list(China_Data['Life Ladder'])\n",
    "# US_Data.sort_values(by = 'Life Ladder', ascending = False)\n",
    "print(len(China_Data))\n",
    "China_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "china = len(China_Data_LL)\n",
    "china_days = 2835\n",
    "china_power = 10\n",
    "PRC_13yr_LL = interploation_1d(China_Data_LL, china, china_days, china_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "China_Stocks = pd.read_csv('Data\\Stocks\\SSE Composite Index (^SSEC)_2006to2017_daily.csv')\n",
    "# China_Stocks\n",
    "PRC_Resulting_Stocks_Data = stocks_data_2(China_Stocks)\n",
    "PRC_Resulting_Stocks_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRC_13yr_LL = pd.DataFrame(data=PRC_13yr_LL)\n",
    "PRC_13yr_LL.columns = ['Daily Life Ladder']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining the 2 Datasets and Do Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRC_Combine = combine_the_data_Stocks_n_LL(PRC_Resulting_Stocks_Data, PRC_13yr_LL)\n",
    "PRC_Combine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## World Happiness Report of India (2006 - 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_excel(\"Data/World Happiness Report/WHR2019.xlsx\", sheet_name='Table2.1')\n",
    "# print(\"(No. of countries, No. of columns) =\", d1.shape)\n",
    "d1 = d1.rename(columns={'country':'Country'})\n",
    "India_Data =  pd.DataFrame(d1[(d1['Country name'] == \"India\")])\n",
    "# print(\"(No. of Years, No. of columns) =\", US_Data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extratcting the Dataset for Happiness and Stocks in India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "India_Data = India_Data[['Year', 'Life Ladder']]\n",
    "India_Data_LL = list(India_Data['Life Ladder'])\n",
    "# US_Data.sort_values(by = 'Life Ladder', ascending = False)\n",
    "print(len(India_Data))\n",
    "India_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "india = len(India_Data_LL)\n",
    "india_days = 3210\n",
    "india_power = 9\n",
    "India_13yr_LL = interploation_1d(India_Data_LL, india, india_days, india_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "India_Stocks = pd.read_csv('Data\\Stocks\\S&P BSE SENSEX (^BSESN)_2006to2018.csv')\n",
    "India_Stocks_Data = stocks_data_2(India_Stocks)\n",
    "India_Stocks_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "India_13yr_LL = pd.DataFrame(data=India_13yr_LL)\n",
    "India_13yr_LL.columns = ['Daily Life Ladder']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining the 2 Datasets and Do Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "India_Combine = combine_the_data_Stocks_n_LL(India_Stocks_Data, India_13yr_LL)\n",
    "India_Combine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## World Happiness Report of Switzerland (2006 - 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_excel(\"Data/World Happiness Report/WHR2019.xlsx\", sheet_name='Table2.1')\n",
    "d1 = d1.rename(columns={'country':'Country'})\n",
    "Swiss_Data =  pd.DataFrame(d1[(d1['Country name'] == \"Switzerland\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extratcting the Dataset for Happiness and Stocks in Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Swiss_Data = Swiss_Data[['Year', 'Life Ladder']]\n",
    "# swiss_Data_LL = list(Swiss_Data['Life Ladder'])\n",
    "print(len(Swiss_Data))\n",
    "Swiss_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Some_list = [pd.Series([2007, 7.49034214], index=Swiss_Data.columns),\n",
    "             pd.Series([2008, 7.507431507], index=Swiss_Data.columns),\n",
    "             pd.Series([2010, 7.6084168753333333333333333333333], index=Swiss_Data.columns),\n",
    "             pd.Series([2011, 7.6923128766666666666666666666667], index=Swiss_Data.columns),\n",
    "             pd.Series([2013, 7.634506226], index=Swiss_Data.columns)]\n",
    "Swiss_Data = Swiss_Data.append(Some_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Swiss_Data.sort_values(by = 'Year', ascending = True)\n",
    "swiss_Data_LL = list(Swiss_Data['Life Ladder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss = len(swiss_Data_LL)\n",
    "swiss_days = 3276\n",
    "swiss_power = 6.75\n",
    "Swiss_8yr_LL = interploation_1d(swiss_Data_LL, swiss, swiss_days, swiss_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Swiss_Stocks = pd.read_csv('Data\\Stocks\\SMI PR (^SSMI)_2006to2018_daily.csv')\n",
    "Swiss_Stocks_Data = stocks_data_2(Swiss_Stocks)\n",
    "Swiss_Stocks_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Swiss_8yr_LL = pd.DataFrame(data=Swiss_8yr_LL)\n",
    "Swiss_8yr_LL.columns = ['Daily Life Ladder']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining the 2 Datasets and Do Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Swiss_Combine = combine_the_data_Stocks_n_LL(Swiss_Stocks_Data, Swiss_8yr_LL)\n",
    "Swiss_Combine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## World Happiness Report of Japan (2006 - 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_excel(\"Data/World Happiness Report/WHR2019.xlsx\", sheet_name='Table2.1')\n",
    "d1 = d1.rename(columns={'country':'Country'})\n",
    "Japan_Data =  pd.DataFrame(d1[(d1['Country name'] == \"Japan\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extratcting the Dataset for Happiness and Stocks in Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Japan_Data = Japan_Data[['Year', 'Life Ladder']]\n",
    "Japan_Data_LL = list(Japan_Data['Life Ladder'])\n",
    "print(len(Japan_Data))\n",
    "Japan_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jap_2006 = [pd.Series([2006, 6.377007484], index=Swiss_Data.columns)]\n",
    "Japan_Data = Swiss_Data.append(Jap_2006, ignore_index=True)\n",
    "Japan_Data.sort_values(by = 'Year', ascending = True)\n",
    "Japan_Data_LL = list(Japan_Data['Life Ladder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jap = len(Japan_Data)\n",
    "jap_days = 3188\n",
    "jap_power = 8.5\n",
    "Jap_LL = interploation_1d(Japan_Data_LL, jap, jap_days, jap_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Japan_Stocks = pd.read_csv(r'Data\\Stocks\\Nikkei 225 (^N225)_2005to2018_daily.csv')\n",
    "Japan_Stocks = Japan_Stocks.dropna()\n",
    "Japan_Stocks_Data = stocks_data_2(Japan_Stocks)\n",
    "# Japan_Stocks_Data = pd.DataFrame(Japan_Stocks_Data)\n",
    "Japan_Stocks_Data.head()\n",
    "# print(len(Japan_Stocks_Data)) 3188 vs 3218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jap_LL = pd.DataFrame(data=Jap_LL)\n",
    "Jap_LL.columns = ['Daily Life Ladder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jap_Combine = combine_the_data_Stocks_n_LL(Japan_Stocks_Data, Jap_LL)\n",
    "Jap_Combine.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
